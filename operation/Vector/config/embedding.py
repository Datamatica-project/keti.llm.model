import faiss
import json
import os
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from typing import List, Dict
import boto3


class Embedder:
    def __init__(self, model_name: str = "dragonkue/snowflake-arctic-embed-l-v2.0-ko", dim: int = 1024):
        self.model = SentenceTransformer(model_name)
        self.index = faiss.IndexFlatL2(dim)  # Cosine similarityëŠ” normalize í•„ìš”
        self.metadata = []


    def add_documents(self, chunks: List[Dict]):
        for chunk in tqdm(chunks, desc="ì„ë² ë”© ë° ì¸ë±ìŠ¤ì— ì¶”ê°€ ì¤‘"):
            text = chunk.get("text", "").strip()
            if not text:
                continue

            # ë²¡í„° ì„ë² ë”©
            vector = self.model.encode([text])  # shape: (1, dim)
            self.index.add(vector)  # FAISSì— ì¶”ê°€

            self.metadata.append({
                "title" : chunk.get("title", ""),
                "text" : text,
                "chunk_id": chunk.get("chunk_id", ""),
                "document": chunk.get("document", ""),
                "source": chunk.get("source", "")
            })

    def save(self, save_dir: str):
        os.makedirs(save_dir, exist_ok=True)

        # FAISS index ì €ì¥
        faiss.write_index(self.index, os.path.join(save_dir, "vector.index"))

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        with open(os.path.join(save_dir, "metadata.json"), "w", encoding="utf-8") as f:
            json.dump(self.metadata, f, ensure_ascii=False, indent=2)

        print(f"ë²¡í„° ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ â†’ {save_dir}")


    def upload_to_minio(
            self,
            bucket: str,
            prefix: str,
            endpoint_url: str,
            access_key: str,
            secret_key: str,
            directory: str = "C:/Users/dm_ohminchan/Model/operation/Vector/index/"  # ğŸ”¥ default directory
    ):
        s3 = boto3.client(
            "s3",
            endpoint_url=endpoint_url,
            aws_access_key_id=access_key,
            aws_secret_access_key=secret_key
        )

        for file_name in ["vector.index", "metadata.json"]:
            file_path = os.path.join(directory, file_name)  # ë””ë ‰í† ë¦¬ ê²½ë¡œ í¬í•¨
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")

            s3.upload_file(file_path, bucket, f"{prefix.rstrip('/')}/{file_name}")
            print(f"ë²¡í„° ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ: {file_name} â†’ {bucket}/{prefix}")